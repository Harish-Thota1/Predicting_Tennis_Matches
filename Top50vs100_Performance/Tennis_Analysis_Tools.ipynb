{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa5f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np                  \n",
    "import pandas as pd                 \n",
    "import matplotlib.pyplot as plt     \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f45947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df):\n",
    "\n",
    "    # Convert 'WRank' and 'LRank' to numeric, coerce errors to NaN\n",
    "    df['WRank'] = pd.to_numeric(df['WRank'], errors='coerce')\n",
    "    df['LRank'] = pd.to_numeric(df['LRank'], errors='coerce')\n",
    "\n",
    "    # Fill missing ranks with a high number (indicative of a very low rank) and convert to float\n",
    "    df['WRank'] = df['WRank'].fillna(100000).astype(float)\n",
    "    df['LRank'] = df['LRank'].fillna(100000).astype(float)\n",
    "\n",
    "    # Determine which player had the higher rank and who won\n",
    "    df['higher_rank_won'] = (df['WRank'] < df['LRank']).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9157877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(actual, predictions):\n",
    "    # Calculate the mean of correct predictions\n",
    "    logr_accuracy_all_predictors = np.round(np.mean(actual == predictions),4)\n",
    "    return logr_accuracy_all_predictors\n",
    "\n",
    "def calibration(actual, predictions):\n",
    "    # Calculate the ratio of the sum of predictions to the sum of actual values\n",
    "    return np.round((np.sum(predictions) / np.sum(actual)), 4)\n",
    "\n",
    "def logloss(actual, predictions):\n",
    "    epsilon = 1e-15  # Small constant to prevent division by zero\n",
    "    # Clip predictions to avoid log of zero. Values are clipped to the range [epsilon, 1-epsilon]\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "    \n",
    "    \n",
    "    logr_logloss_all_predictors = -(1 / len(actual)) * np.sum(\n",
    "        actual * np.log(predictions) + (1 - actual) * np.log(1 - predictions))\n",
    "    return np.round(logr_logloss_all_predictors, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72fd87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating predictions using accuracy, calibration and logloss\n",
    "def evaluate_predictions(actual_outcomes, binary_predictions, probability_predictions):\n",
    "    accuracy_result = accuracy(actual_outcomes, binary_predictions)\n",
    "    \n",
    "    calibration_result = calibration(actual_outcomes, probability_predictions)\n",
    "    \n",
    "    logloss_result = logloss(actual_outcomes, probability_predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_result,  \n",
    "        'calibration': calibration_result,  \n",
    "        'log_loss': logloss_result  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e65fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_top_players(data, top_n):\n",
    "    # Group data by year, then find top n players based on 'WRank' and 'LRank' for winners and losers.\n",
    "    top_players_by_year = {}\n",
    "    for year, group in data.groupby(data['Date'].dt.year):\n",
    "        top_winners = set(group.nsmallest(top_n, 'WRank')['Winner'].unique())\n",
    "        top_losers = set(group.nsmallest(top_n, 'LRank')['Loser'].unique())\n",
    "        top_players_by_year[year] = top_winners.union(top_losers)\n",
    "    return top_players_by_year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
